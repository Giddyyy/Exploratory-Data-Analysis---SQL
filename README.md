# DataAnalytics-Assessment

# ðŸ“Š Overview
This project focuses on analyzing customer behavior and financial activity using SQL. 

The data spans across multiple tables, including customer details, savings account transactions, and investment plans and withdrawal transactions.

The goal is to derive actionable insights for cross-selling, transaction behavior, inactivity monitoring, and customer lifetime value estimation.

## ðŸ“ Tables Used
~ users_customuser â€“ Contains customer demographic and contact information.

~ savings_savingsaccount â€“ Contains records of deposit transactions.

~ plans_plan â€“ Contains records of plans created by customers including whether a plan is a regular savings or an investment fund.

### ðŸ§© Q1: Cross-Selling Opportunity
Objective: Identify customers with funded savings and investment plans, to target for cross-sell campaigns.

Approach:

  â€¢	Filter plans_plan where:
  
      â€¢	is_regular_savings = 1 for savings
      
      â€¢	is_a_fund = 1 for investments
  
  â€¢	Join with savings_savingsaccount to check for confirmed inflows (confirmed_amount > 0).
  
  â€¢	Count distinct funded plans per type (savings vs investment) per customer.
  
  â€¢	Sum total deposits using confirmed_amount.

  â€¢ Converted total deposits from kobo to naira and rounded up.
  
  â€¢	Final query summary:
  
    -->	owner_id | full name | savings_count | investment_count | total_deposits

### ðŸ§© Q2: Transaction Frequency Analysis

Objective: Segment customers based on how often they transact monthly.

Approach:

  â€¢	Limit to the last 12 months of data while storing into a temp table (cte) to be able to call it back for reference in the following subqueries.
  
  â€¢	Used a CASE statement to categorize:
  
      â€¢	High Frequency: â‰¥10/month
      
      â€¢	Medium Frequency: 3â€“9/month
      
      â€¢	Low Frequency: â‰¤2/month
  
  â€¢	Count total transactions per customer, divide by 12 to get average monthly frequency.
  
  â€¢	Group and count customers in each frequency category.
  
  â€¢	Used ROUND() to format average values cleanly.
  
  â€¢	Final query summary:
  
    --> frequency_category | customer_count | avg_transactions_per_month

### ðŸ§© Q3: Account Inactivity Alert

Objective: Detect savings or investment accounts that havenâ€™t had any inflow for over a year.

Approach:

  â€¢	Join savings_savingsaccount with plans_plan to determine account type.
  
  â€¢	Used MAX(transaction_date) per plan to find the last activity.
  
  â€¢	Calculate inactivity_days.
  
  â€¢	Filter for accounts with inactivity_days > 365 to flag long-term inactivity.
  
  â€¢	Final query summary:
  
    --> plan_id | owner_id | account type | last_transaction_date | no. of days inactive

### ðŸ§© Q4: Customer Lifetime Value (CLV)

Objective: Estimate how much value each customer brings over their account lifetime.

Approach:

â€¢	Used TIMESTAMPDIFF(MONTH, u.date_joined, CURRENT_DATE) to calculate account tenure.

â€¢	Count total transactions per customer.

â€¢	Assume profit per transaction = 0.1% of value.

â€¢	CLV formula: CLV = (total_transactions / tenure_months) * 12 * avg_profit_per_transaction

â€¢	Ensure division safety using NULLIF(tenure, 0) to avoid errors.

â€¢	Final query summary:

    --> customer_id | full name | tenure_months | total_transactions | estimated_clv

## ðŸ’¡ Challenges and Solutions

### 1. Query Structuring & Readability

â€¢ Challenge: Queries became complex, especially when categorizing or computing over derived values.

â€¢ Solution: Broke queries into modular CTEs (Common Table Expressions) for clarity and reusability, then combined them into final outputs

### 2. SQL Function Compatibility

â€¢	Challenge: Some SQL functions like DATE_TRUNC were not supported in my environment.

â€¢	Solution: Replaced with portable alternatives like:

    --> DATE_FORMAT(current_date, '%Y-%m-01')

to simulate monthly truncation in MySQL

### 3. Syntax & Debugging Errors

â€¢	Challenge: Faced multiple errors due to:

  â€¢	Misplaced parentheses (e.g., in ROUND())
  
  â€¢	Incorrect CASE syntax 

â€¢	Solution: Resolved by isolating subqueries, testing piece by piece, and cleaning up SQL syntax as in order.

### 4. Partial User Representation in Outputs

â€¢	Challenge: Not all users from users_customuser appeared in transaction-based outputs. This was evident in Q3 as the total customer count in the results did not tally with the overall registered users.

â€¢	Reason: Only customers with valid transactions in the last 12 months were counted in frequency or CLV tasks.

â€¢	Solution: Clarified scope and aligned expectations accordingly â€” results were intentional subsets, not total population metrics.

## ðŸ§  General Approach

For each analysis task, I followed a structured and repeatable process to ensure clarity, accuracy, and adaptability:

### 1. Understand the Business Scenario

  Each task began with a clear understanding of the business goal.

### 2. Inspect Data Structure

I reviewed all relevant tables (users_customuser, savings_savingsaccount, plans_plan) to:

  â€¢	Identify necessary fields
  
  â€¢	Understand foreign key relationships
  
  â€¢	Note available data types (dates, booleans, monetary values)

### 3. Define Metrics Clearly

For each output column (e.g., total_deposits, tenure_months, frequency_category), I:

  â€¢	Established logic for calculation
  
  â€¢	Verified assumptions and given parameters (e.g., inflow = confirmed_amount).

### 4. Build Step-by-Step Queries
  
  Rather than writing complex queries all at once, I:
  
  â€¢	Built each column independently
  
  â€¢	Validated results and assumptions
  
  â€¢	Gradually combined them into a full query, often using CTEs for clarity where necessary

### 5. Handle Edge Cases and Data Quality

  â€¢	Ensured monetary values were converted from kobo to naira
  
  â€¢	Filtered transactions by recency or status when relevant
  
  â€¢	Used COALESCE and conditional logic to handle nulls and prevent skewed results

### 6. Test and Refine

Every query was tested iteratively:

  â€¢	Debugged errors (syntax, logic, joins)
  
  â€¢	Compared intermediate outputs against expectations
  
  â€¢	Cleaned and structured the final results to match business-friendly formats

### 7. Document the Query

Each query includes clear inline comments to explain:
  
  â€¢	Joins and filters
  
  â€¢	Aggregations and logic
  
  â€¢	Business reasoning (e.g., why a certain threshold or classification is used)

## âœ… Tools & Skills Demonstrated
  
  â€¢	SQL Joins & Aggregations
  
  â€¢	CTE usage
  
  â€¢	Conditional logic (CASE)
  
  â€¢	Date and time calculations
  
  â€¢	Data cleaning and formatting (e.g., kobo to naira)
  
  â€¢	Customer segmentation logic

